{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91afdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a947334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_stock.csv', parse_dates=['Date'])\n",
    "df = df.sort_values('Date').set_index('Date')\n",
    "\n",
    "price_col = 'Adj Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e7a57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open   High        Low      Close  Adj Close  Volume\n",
      "Date                                                                 \n",
      "2015-09-22  27.049999  27.48  26.620001  26.830000  26.830000     0.0\n",
      "2017-09-01  16.969999  17.00  16.580000  16.860001  16.860001     0.0\n"
     ]
    }
   ],
   "source": [
    "# rows where any numeric column equals 0\n",
    "zero_row = df[(df.select_dtypes(include=[np.number]) == 0).any(axis=1)]\n",
    "print(zero_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "95fa6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(0, np.nan)\n",
    "df = df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "486287da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_ret'] = np.log(df[price_col] / df[price_col].shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe6d1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "\n",
    "    df['ret_1'] = df['log_ret']\n",
    "    df['ret_2'] = df['log_ret'].shift(1)\n",
    "    df['ret_5'] = df[price_col].pct_change(5)\n",
    "\n",
    "\n",
    "    df['vol_5'] = df['log_ret'].rolling(5).std()\n",
    "    df['vol_10'] = df['log_ret'].rolling(10).std()\n",
    "\n",
    "\n",
    "    df['momentum_5'] = df[price_col] / df[price_col].shift(5) - 1\n",
    "    df['momentum_10'] = df[price_col] / df[price_col].shift(10) - 1\n",
    "\n",
    "\n",
    "    df['volume_change'] = df['Volume'].pct_change()\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60fdc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.9)\n",
    "\n",
    "\n",
    "train_raw = df.iloc[:train_size]\n",
    "test_raw = df.iloc[train_size:]\n",
    "\n",
    "\n",
    "train = make_features(train_raw).dropna()\n",
    "test = make_features(test_raw).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ccbeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[price_col, 'log_ret'])\n",
    "y_train = train['log_ret'].shift(-1).dropna()\n",
    "\n",
    "\n",
    "X_train = X_train.iloc[:-1]\n",
    "\n",
    "\n",
    "X_test = test.drop(columns=[price_col, 'log_ret'])\n",
    "y_test = test['log_ret'].shift(-1).dropna()\n",
    "\n",
    "\n",
    "X_test = X_test.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9411e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    direction = np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "    print(f\"{name} | RMSE(ret): {rmse:.6f} | Direction Acc: {direction:.3f}\")\n",
    "\n",
    "def evaluate_price(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name} | RMSE(price): {rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8415f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_price(last_price, returns):\n",
    "    prices = []\n",
    "    p = last_price\n",
    "    for r in returns:\n",
    "        p = p * np.exp(r)\n",
    "        prices.append(p)\n",
    "        return prices\n",
    "\n",
    "last_price = train_raw[price_col].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "984c740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression | RMSE(ret): 0.036739 | Direction Acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train_s, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_s)\n",
    "\n",
    "evaluate(y_test, y_pred_ridge, \"Ridge Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3625471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest | RMSE(ret): 0.035900 | Direction Acc: 0.523\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "n_estimators=600,\n",
    "max_depth=6,\n",
    "min_samples_leaf=20,\n",
    "max_features=0.5,\n",
    "random_state=42,\n",
    "n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d4b05865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost | RMSE(ret): 0.035841 | Direction Acc: 0.509\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "n_estimators=800,\n",
    "max_depth=4,\n",
    "learning_rate=0.02,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.8,\n",
    "objective='reg:squarederror',\n",
    "random_state=42,\n",
    "early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "\n",
    "xgb.fit(\n",
    "X_train, y_train,\n",
    "eval_set=[(X_test, y_test)],\n",
    "verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred_xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da400a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA | RMSE(ret): 0.036052 | Direction Acc: 0.417\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Prepare return series\n",
    "y_full = np.log(df[price_col]).diff().dropna()\n",
    "y_train_arima = y_full.iloc[:train_size-1]\n",
    "y_test_arima = y_full.iloc[train_size-1:train_size-1+len(y_test)]\n",
    "\n",
    "\n",
    "history = y_train_arima.tolist()\n",
    "y_pred_arima = []\n",
    "\n",
    "\n",
    "for t in range(len(y_test_arima)):\n",
    "    model = ARIMA(history, order=(1,0,1))\n",
    "    fit = model.fit()\n",
    "    yhat = fit.forecast()[0]\n",
    "    y_pred_arima.append(yhat)\n",
    "    history.append(y_test_arima.iloc[t])\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "evaluate(y_test_arima.values, np.array(y_pred_arima), 'ARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b14b2aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002465DE42F20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "LSTM | RMSE(ret): 0.037019 | Direction Acc: 0.495\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "window = 30\n",
    "features_lstm = X_train.columns.tolist()\n",
    "\n",
    "\n",
    "# Build sequences\n",
    "def make_sequences(X, y, window):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window):\n",
    "        Xs.append(X.iloc[i:i+window].values)\n",
    "        ys.append(y.iloc[i+window])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "Xtr_seq, ytr_seq = make_sequences(X_train, y_train, window)\n",
    "\n",
    "\n",
    "X_test_ext = pd.concat([X_train.iloc[-window:], X_test])\n",
    "y_test_ext = pd.concat([y_train.iloc[-window:], y_test])\n",
    "\n",
    "Xte_seq, yte_seq = make_sequences(X_test_ext, y_test_ext, window)\n",
    "1\n",
    "\n",
    "scaler_lstm = StandardScaler()\n",
    "\n",
    "Xtr_seq = scaler_lstm.fit_transform(\n",
    "    Xtr_seq.reshape(-1, Xtr_seq.shape[-1])\n",
    ").reshape(Xtr_seq.shape)\n",
    "\n",
    "Xte_seq = scaler_lstm.transform(\n",
    "    Xte_seq.reshape(-1, Xte_seq.shape[-1])\n",
    ").reshape(Xte_seq.shape)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(window, Xtr_seq.shape[-1])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(Xtr_seq, ytr_seq, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "y_pred_lstm = model.predict(Xte_seq).flatten()\n",
    "evaluate(yte_seq, y_pred_lstm, 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f36091d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "prophet_train = train[[price_col]].copy()\n",
    "# prophet_train['Date'] = prophet_train.index\n",
    "prophet_train = prophet_train.reset_index().rename(columns={'Date': 'ds', price_col: 'y'})\n",
    "\n",
    "prophet_test = test[[price_col]].copy()\n",
    "# prophet_test['Date'] = prophet_test.index\n",
    "prophet_test = prophet_test.reset_index().rename(columns={'Date': 'ds', price_col: 'y'})\n",
    "\n",
    "model = Prophet(\n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    seasonality_mode='multiplicative',   # important for prices\n",
    "    changepoint_prior_scale=0.05          # controls trend flexibility\n",
    ")\n",
    "\n",
    "model.fit(prophet_train)\n",
    "\n",
    "future = model.make_future_dataframe(periods=len(prophet_test), freq='B')\n",
    "forecast = model.predict(future)\n",
    "forecast_test = forecast.iloc[-len(prophet_test):].copy()\n",
    "forecast_test.index = prophet_test.index\n",
    "\n",
    "y_true = prophet_test['y']\n",
    "y_pred = forecast_test['yhat']\n",
    "\n",
    "# evaluate_price(y_true, y_pred, 'Prophet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67656be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [186, 216]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m start_price_lstm \u001b[38;5;241m=\u001b[39m make_price_path(last_price, y_test\u001b[38;5;241m.\u001b[39mvalues[:window])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     28\u001b[0m price_true_lstm \u001b[38;5;241m=\u001b[39m make_price_path(start_price_lstm, y_test\u001b[38;5;241m.\u001b[39mvalues[window:])\n\u001b[0;32m     29\u001b[0m price_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE (price)\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_true_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_price_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_price_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_lstm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     32\u001b[0m })\n\u001b[0;32m     34\u001b[0m price_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProphet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE (price)\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_true, y_pred))\n\u001b[0;32m     37\u001b[0m })\n\u001b[0;32m     39\u001b[0m price_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(price_results)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE (price)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 111\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [186, 216]"
     ]
    }
   ],
   "source": [
    "def make_price_path(start_price, returns):\n",
    "    return start_price * np.exp(np.cumsum(returns))\n",
    "\n",
    "price_results = []\n",
    "\n",
    "price_true = make_price_path(last_price, y_test.values)\n",
    "price_results.append({\n",
    "    'Model': 'Ridge',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(price_true, make_price_path(last_price, y_pred_ridge)))\n",
    "})\n",
    "price_results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(price_true, make_price_path(last_price, y_pred_rf)))\n",
    "})\n",
    "price_results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(price_true, make_price_path(last_price, y_pred_xgb)))\n",
    "})\n",
    "\n",
    "start_price_arima = df[price_col].iloc[train_size-1]\n",
    "price_true_arima = make_price_path(start_price_arima, y_test_arima.values)\n",
    "price_results.append({\n",
    "    'Model': 'ARIMA',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(price_true_arima, make_price_path(start_price_arima, y_pred_arima)))\n",
    "})\n",
    "\n",
    "start_price_lstm = make_price_path(last_price, y_test.values[:window])[-1]\n",
    "price_true_lstm = make_price_path(start_price_lstm, y_test.values[window:])\n",
    "price_results.append({\n",
    "    'Model': 'LSTM',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(price_true_lstm, make_price_path(start_price_lstm, y_pred_lstm)))\n",
    "})\n",
    "\n",
    "price_results.append({\n",
    "    'Model': 'Prophet',\n",
    "    'RMSE (price)': np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "})\n",
    "\n",
    "price_results_df = pd.DataFrame(price_results).sort_values('RMSE (price)')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(price_results_df['Model'], price_results_df['RMSE (price)'])\n",
    "plt.title('Model Comparison – RMSE on Price')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d9c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (186) does not match length of index (217)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m price_pred_xgb \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(make_price_path(last_price, y_pred_xgb), index\u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      5\u001b[0m price_pred_arima \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(make_price_path(start_price_arima, y_pred_arima), index\u001b[38;5;241m=\u001b[39my_test_arima\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m----> 6\u001b[0m price_pred_lstm \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_price_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_price_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_lstm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m price_pred_prophet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_pred, index\u001b[38;5;241m=\u001b[39my_true\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:575\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    573\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 575\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (186) does not match length of index (217)"
     ]
    }
   ],
   "source": [
    "# Compare predicted price paths vs actual\n",
    "price_pred_ridge = pd.Series(make_price_path(last_price, y_pred_ridge), index=y_test.index)\n",
    "price_pred_rf = pd.Series(make_price_path(last_price, y_pred_rf), index=y_test.index)\n",
    "price_pred_xgb = pd.Series(make_price_path(last_price, y_pred_xgb), index=y_test.index)\n",
    "price_pred_arima = pd.Series(make_price_path(start_price_arima, y_pred_arima), index=y_test_arima.index)\n",
    "price_pred_lstm = pd.Series(make_price_path(start_price_lstm, y_pred_lstm), index=y_true.index)\n",
    "price_pred_prophet = pd.Series(y_pred, index=y_true.index)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y_test.index, price_true, label='Actual Price', linewidth=2)\n",
    "plt.plot(price_pred_ridge.index, price_pred_ridge, label='Ridge')\n",
    "plt.plot(price_pred_rf.index, price_pred_rf, label='Random Forest')\n",
    "plt.plot(price_pred_xgb.index, price_pred_xgb, label='XGBoost')\n",
    "plt.title('Actual vs Predicted Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
